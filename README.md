# Effects of Observation Dependence on Eye Color Prediction Accuracy (Logistic Regression vs. Hierarchical Bayesian Inference)

## Overview

This project investigates the performance of traditiona $k$-means clustering and hierarchical clustering on SNP data.

## Contents

All data will be available in `data` To avoid the curse of dimensionality, we determine the top $p$ principal components and use those for our clusterings. We also explore the extent to which various SNPs contributed to each principal component.

Before training and testing the models in question, we perform LD pruning to get rid of any SNPs that would be correlated in minor allele frequency for reasons obviously unrelated to eye color contributions. We use `plink` to meet this end, and the scripts for doing so are available in `scripts`.

The model analysis that follows is compact enough to be included in `notebooks/model_analysis.ipynb`, which you can interact with locally to see the various components involved:
* data loading / preprocessing / exploration (TODO)
    - At this point, the data has already been generated by `plink`; we just load the resulting feature matrix and point labels with `pandas`. There is not much special preprocessing involved here.
* clustering
    - Here, we cluster the data using $k$-means and hierarchical clustering. We plot the resulting clusters and explore the differences in the structure that the two methods are able to discover.

## Usage

The script `scripts/pipe.sh` runs the entire pipeline:
* PCA with `plink`
* notebook execution
* notebook export to markdown

you can specify two optional parameters, $p$ (number of principal components) and $k$ (maximum number of clusters to test during hyperparameter tuning).