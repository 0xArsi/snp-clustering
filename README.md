# Effects of Observation Dependence on Eye Color Prediction Accuracy (Logistic Regression vs. Hierarchical Bayesian Inference)

## Overview

This project investigates the performance of traditiona $k$-means clustering and hierarchical clustering on SNP data.

## Contents

All data will be available in `data` To avoid the curse of dimensionality, we determine the top $p$ principal components and use those for our clusterings. We also explore the extent to which various SNPs contributed to each principal component.

The model analysis that follows is compact enough to be included in `notebooks/model_analysis.ipynb`, which you can interact with locally to see the various components involved:
* data loading / preprocessing / exploration (TODO)
    - At this point, the data has already been generated by `plink`; we just load the resulting feature matrix and point labels with `pandas`. There is not much special preprocessing involved here.
* clustering
    - Here, we cluster the data using $k$-means and hierarchical clustering. We plot the resulting clusters and explore the differences in the structure that the two methods are able to discover.

## Usage


The script `scripts/pipe.sh` runs the entire pipeline:
* PCA with `plink`
* notebook execution
* notebook export to markdown

you can specify two optional parameters, $p$ (number of principal components) and $k$ (maximum number of clusters to test during hyperparameter tuning).

This analysis uses `plink`, `numpy`, `pandas`, and `scikit-learn`. The pipe script will create an environment containing these dependencies and run the analysis within. 