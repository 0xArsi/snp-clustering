# Comparison of Lightweight Methods for Clustering on SNP Data ($k$-means vs. hierarchical)

## Overview

This project investigates the performance of traditiona $k$-means clustering and hierarchical clustering on SNP data.

## Contents

All data will be available in `data` To avoid the curse of dimensionality, we determine the top $p$ principal components and use those for our clusterings. We also explore the extent to which various SNPs contributed to each principal component.

The model analysis that follows is compact enough to be included in `notebooks/model_analysis.ipynb`, which you can interact with locally to see the various components involved:
* data loading / preprocessing / exploration (TODO)
    - At this point, the data has already been generated by `plink`; we just load the resulting feature matrix and point labels with `pandas`. There is not much special preprocessing involved here.
* clustering
    - Here, we cluster the data using $k$-means and hierarchical clustering. We plot the resulting clusters and explore the differences in the structure that the two methods are able to discover.

## Usage


The script `scripts/pipe.sh` runs the entire pipeline:
* PCA with `plink`
* clustering and visualization
* notebook export to markdown

you can specify two optional parameters, $p$ (number of principal components) and $k$ (maximum number of clusters to test during hyperparameter tuning):

`bash scripts/pipe.sh -p <num_principal_components> -k <max_number_of_clusters>`

This analysis depends on:
* `plink` for PCA and SNP variance weighting
* `numpy` and `pandas` for data manipulation 
* `scikit-learn` for clustering
* `matplotlib` for plotting 
* `papermill` and `nbconvert` for notebook execution/export

The pipe script will create an environment containing these dependencies and run the analysis within. 